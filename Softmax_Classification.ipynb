{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Softmax Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**import**"
      ],
      "metadata": {
        "id": "y9ck1wDklAn3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZmUU_eyk2RL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For reproducibility\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ExJK-QlI5e",
        "outputId": "4986d10a-c902-46ba-a509-20bedb4ea3bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd7f3e60af0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax**"
      ],
      "metadata": {
        "id": "PGxfi8Ronago"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.FloatTensor([1,2,3])"
      ],
      "metadata": {
        "id": "Ijuk5DnvnXOy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = F.softmax(z, dim = 0 )\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeHdsCXynqoB",
        "outputId": "74d4656f-a23b-4e8b-eea8-139dab87e1c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HViuEDajobLx",
        "outputId": "a2eaef4e-874d-48e0-b969-1cf437b757c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Entropy Loss (Low-Level)"
      ],
      "metadata": {
        "id": "Nst9-u3eowzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.rand(3, 5, requires_grad = True) # classes = 5, samples = 3\n",
        "hypothesis = F.softmax(z, dim = 1)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAijK2g2ojSB",
        "outputId": "19826162-27f0-43b7-c736-38625dcc515a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2974, 0.2244, 0.1595, 0.1420, 0.1767],\n",
            "        [0.1509, 0.1595, 0.1917, 0.2522, 0.2457],\n",
            "        [0.1002, 0.2226, 0.1878, 0.2624, 0.2271]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.randint(5,(3,)).long()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMlpxz9I0k-D",
        "outputId": "0e730829-4734-4da1-b098-cf2eed015a5f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1),1) # dim =1에서 unsqueeze를 통해서 1을 뿌림"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiNx7a9o1Dsi",
        "outputId": "98d3c202-b40b-4932-c901-c4722340b0cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdGGFr5A161z",
        "outputId": "46977d83-cfc2-4f49-c464-327026d503d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.6471, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-entropy Loss with torch.nn.functional"
      ],
      "metadata": {
        "id": "_uPuByV624JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Low level\n",
        "torch.log(F.softmax(z, dim = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5wwdZeS22tT",
        "outputId": "ad0a0874-70b6-4ea9-b56a-fafb61a76c8b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2127, -1.4941, -1.8359, -1.9517, -1.7335],\n",
              "        [-1.8912, -1.8358, -1.6516, -1.3775, -1.4038],\n",
              "        [-2.3011, -1.5023, -1.6726, -1.3380, -1.4823]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# High level\n",
        "F.log_softmax(z, dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv5-UIII3Bar",
        "outputId": "8c34b160-85db-4612-903b-b54b36e6c8c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2127, -1.4941, -1.8359, -1.9517, -1.7335],\n",
              "        [-1.8912, -1.8358, -1.6516, -1.3775, -1.4038],\n",
              "        [-2.3011, -1.5023, -1.6726, -1.3380, -1.4823]],\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Low level\n",
        "(y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDhBUuYs3O9D",
        "outputId": "9628ff22-1b70-4ebc-f32f-1a725526ea87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6471, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# High level\n",
        "F.nll_loss(F.log_softmax(z, dim =1),y ) # nll = negative log likelihood"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gawyxWm3V6T",
        "outputId": "3bea4783-ed93-4d8a-a1ca-48963ed811a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6471, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(z, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACZ0iU5K3pNT",
        "outputId": "11161c00-af4e-4099-e620-1c510252de23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6471, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with Low-level Cross Entropy Loss"
      ],
      "metadata": {
        "id": "BKs7xpwl38XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = [[1, 2, 1, 1],\n",
        "           [2, 1, 3, 2],\n",
        "           [3, 1, 3, 4],\n",
        "           [4, 1, 5, 5],\n",
        "           [1, 7, 5, 5],\n",
        "           [1, 2, 5, 6],\n",
        "           [1, 6, 6, 6],\n",
        "           [1, 7, 7, 7]]\n",
        "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)"
      ],
      "metadata": {
        "id": "kWUOgbP_4CSZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# samples = m\n",
        "# classes = 3\n",
        "# dim = 4 \n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4,3), requires_grad= True)\n",
        "b = torch.zeros(1, requires_grad= True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # Cost 계산 (1)\n",
        "  hypothesis = F.softmax(x_train.matmul(W)+ b, dim =1 ) # or .nn \n",
        "  y_one_hot = torch.zeros_like(hypothesis)\n",
        "  y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
        "  cost = (y_one_hot * -torch.log(F.softmax(hypothesis, dim = 1))).sum(dim=1).mean()\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력 \n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5hYxtBJ4GdL",
        "outputId": "a405f739-97bb-4ff9-dacd-e6a0ac37751c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.901535\n",
            "Epoch  200/1000 Cost: 0.839114\n",
            "Epoch  300/1000 Cost: 0.807826\n",
            "Epoch  400/1000 Cost: 0.788472\n",
            "Epoch  500/1000 Cost: 0.774822\n",
            "Epoch  600/1000 Cost: 0.764449\n",
            "Epoch  700/1000 Cost: 0.756191\n",
            "Epoch  800/1000 Cost: 0.749398\n",
            "Epoch  900/1000 Cost: 0.743671\n",
            "Epoch 1000/1000 Cost: 0.738749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trining with F.cross_entropy**"
      ],
      "metadata": {
        "id": "8qFEMbPW7mDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# samples = m\n",
        "# classes = 3\n",
        "# dim = 4 \n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((4,3), requires_grad= True)\n",
        "b = torch.zeros(1, requires_grad= True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr = 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # Cost 계산 (2)\n",
        "  z = x_train.matmul(W) + b\n",
        "  cost= F.cross_entropy(z, y_train)\n",
        "  \n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력 \n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-vs442O7kg8",
        "outputId": "f7da732c-ac78-4cf0-e823-016d92a4c306"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.098612\n",
            "Epoch  100/1000 Cost: 0.761050\n",
            "Epoch  200/1000 Cost: 0.689991\n",
            "Epoch  300/1000 Cost: 0.643229\n",
            "Epoch  400/1000 Cost: 0.604117\n",
            "Epoch  500/1000 Cost: 0.568256\n",
            "Epoch  600/1000 Cost: 0.533922\n",
            "Epoch  700/1000 Cost: 0.500291\n",
            "Epoch  800/1000 Cost: 0.466908\n",
            "Epoch  900/1000 Cost: 0.433507\n",
            "Epoch 1000/1000 Cost: 0.399962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**High-level Implementation with nn.Module**"
      ],
      "metadata": {
        "id": "Cl5pem4i60ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(4,3) # 4개의 input을 받아서 3개의 class에대한 각각의 확률값을 뱉어냄 Output이 3\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "Vh5SrzZd6zET"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()"
      ],
      "metadata": {
        "id": "e0yQ6tpr8iOU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr= 0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction = model(x_train)\n",
        "  # Cost 계산\n",
        "  cost= F.cross_entropy(prediction, y_train)\n",
        "  \n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력 \n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP1qzHw28l-u",
        "outputId": "6216cb75-3853-42ea-88c7-047ff0c09b19"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 1.777960\n",
            "Epoch  100/1000 Cost: 0.654127\n",
            "Epoch  200/1000 Cost: 0.561501\n",
            "Epoch  300/1000 Cost: 0.505037\n",
            "Epoch  400/1000 Cost: 0.460010\n",
            "Epoch  500/1000 Cost: 0.420253\n",
            "Epoch  600/1000 Cost: 0.383131\n",
            "Epoch  700/1000 Cost: 0.347032\n",
            "Epoch  800/1000 Cost: 0.310779\n",
            "Epoch  900/1000 Cost: 0.274060\n",
            "Epoch 1000/1000 Cost: 0.244281\n"
          ]
        }
      ]
    }
  ]
}