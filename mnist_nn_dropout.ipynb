{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_nn_dropout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtyilEcr/SHj5w7pfII5Iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlgns8469/Pytorch_Tutorial/blob/main/mnist_nn_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BtlOu2Mvc4Lg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "a737fublf86K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "drop_prob = 0.3"
      ],
      "metadata": {
        "id": "Vdky-RHPgVH5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root = 'MNIST_data/', train = True, transform = transforms.ToTensor(), download = True)\n",
        "mnist_test = dsets.MNIST(root = 'MNIST_data/', train = False, transform = transforms.ToTensor(), download = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ucosZrLth1Na"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, batch_size = batch_size, shuffle = True, drop_last= True)"
      ],
      "metadata": {
        "id": "p1FtCQMehpYB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn layers\n",
        "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
        "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear5 = torch.nn.Linear(512, 10, bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "dropout = torch.nn.Dropout(p=drop_prob)"
      ],
      "metadata": {
        "id": "1_xaNIqoik3q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xavier initialization\n",
        "torch.nn.init.xavier_uniform_(linear1.weight)\n",
        "torch.nn.init.xavier_uniform_(linear2.weight)\n",
        "torch.nn.init.xavier_uniform_(linear3.weight)\n",
        "torch.nn.init.xavier_uniform_(linear4.weight)\n",
        "torch.nn.init.xavier_uniform_(linear5.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lou5ZaBAkuPQ",
        "outputId": "8c62f9a2-3bab-48e3-f310-ae80557959a4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0162,  0.0993, -0.0999,  ...,  0.0987,  0.1026,  0.0644],\n",
              "        [-0.0315,  0.0519,  0.0047,  ..., -0.0434, -0.0674, -0.0864],\n",
              "        [ 0.0205, -0.0268,  0.0343,  ..., -0.0204,  0.0603, -0.0989],\n",
              "        ...,\n",
              "        [ 0.0327,  0.0965, -0.0909,  ..., -0.1048, -0.0263, -0.0621],\n",
              "        [-0.0821,  0.0444,  0.0772,  ...,  0.0694, -0.0743, -0.0347],\n",
              "        [ 0.0247, -0.0514, -0.0832,  ..., -0.0021, -0.0081, -0.0917]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = torch.nn.Sequential(linear1, relu, dropout,\n",
        "                            linear2, relu, dropout,\n",
        "                            linear3, relu, dropout,\n",
        "                            linear4, relu, dropout,\n",
        "                            linear5).to(device)"
      ],
      "metadata": {
        "id": "82VkVWCqktUq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cost/loss & optimizer\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device) #softmax is internally computed\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ],
      "metadata": {
        "id": "Sf4r6E2JlXA3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "model.train()    # set the model to train mode (dropout=True)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "\n",
        "  for X, Y in data_loader:\n",
        "    # reshape input image into [batch_size by 784]\n",
        "    # label is not one-hot encoded\n",
        "\n",
        "    X = X.view(-1,28*28).to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    avg_cost += cost/total_batch\n",
        "\n",
        "  print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2BuXG3_l7zi",
        "outputId": "25250c76-7511-43c4-f374-14d41e0f41c9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost = 0.118606322\n",
            "Epoch: 0002 cost = 0.099474385\n",
            "Epoch: 0003 cost = 0.087634511\n",
            "Epoch: 0004 cost = 0.074999295\n",
            "Epoch: 0005 cost = 0.071235977\n",
            "Epoch: 0006 cost = 0.067324884\n",
            "Epoch: 0007 cost = 0.058357265\n",
            "Epoch: 0008 cost = 0.054274853\n",
            "Epoch: 0009 cost = 0.053862140\n",
            "Epoch: 0010 cost = 0.051085413\n",
            "Epoch: 0011 cost = 0.049557596\n",
            "Epoch: 0012 cost = 0.045947447\n",
            "Epoch: 0013 cost = 0.038892940\n",
            "Epoch: 0014 cost = 0.043740097\n",
            "Epoch: 0015 cost = 0.040953036\n",
            "Learning finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model useing test sets\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  model.eval()    # set the model to evaluation mode (dropout=False)\n",
        "  \n",
        "  X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
        "  Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "  prediction = model(X_test)\n",
        "  correct_prediction = torch.argmax(prediction, 1)== Y_test\n",
        "  accuracy= correct_prediction.float().mean()\n",
        "  print('Accuracy: ', accuracy.item() )\n",
        "\n",
        "  # Get one and predict\n",
        "  r= random.randint(0, len(mnist_test) - 1)\n",
        "  X_single_data = mnist_test.test_data[r:r+1].view(-1, 28*28).float().to(device)\n",
        "  Y_single_data = mnist_test.test_labels[r:r+1].to(device)\n",
        "\n",
        "  print('Label: ', Y_single_data.item())\n",
        "  single_prediction = model(X_single_data)\n",
        "  print('Prediction: ', torch.argmax(single_prediction,1).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PEuulnHph5g",
        "outputId": "7fed663b-ef4c-49e1-8328-35716127f45b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9800999760627747\n",
            "Label:  5\n",
            "Prediction:  5\n"
          ]
        }
      ]
    }
  ]
}